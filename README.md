<a href="https://www.gnu.org/licenses/gpl-3.0"><img src="https://img.shields.io/badge/License-GPLv3-blue.svg" alt="License"></a>
<a href="mailto:najemabdennour@gmail.com"><img src="https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg" alt="Ask Me Anything"></a>
<a href="https://www.python.org/"><img src="https://img.shields.io/badge/Made%20with-Python-1f425f.svg" alt="Made with Python"></a>
<a href="https://pedromargolles.github.io/pyDecNef/"><img src="https://img.shields.io/badge/Documentation-pyDecNef-red.svg" alt="Documentation"></a>
<a href="https://doi.org/10.1101/2025.02.21.639408"><img src="https://img.shields.io/badge/Citation-DOI-green.svg" alt="Citation"></a>
<br></br>

<p align="center">
  <img src="https://pedromargolles.github.io/pyDecNef/assets/images/wide_logo2.png">
</p>

## About:


PyDecNef2.0 includes an intuitive and efficient Python framework for real-time fMRI decoded neurofeedback, integrating various machine learning techniques as in [figure 1](ML), including co-adaptation and Bayesian optimization algorithms to improve the feedback signal provided to participants and enhance the learning curves during neurofeedback training. This library is a continuation of the PyDecNef project [link](https://github.com/pedromargolles/pyDecNef), that incorporated scripts for fMRI volumes pre-processing, decoder construction, data post-processing and a full pipeline for neurofeedback training.

![ML](.img/ML_performance_comparison.png)

PyDecNef2.0: is an open-source, Python-based real-time fMRI decoded neurofeedback framework, that supports extensive customization and personalization for various experimental setups.

**For more information and tutorials visit [pyDecNef project webpage](https://pedromargolles.github.io/pyDecNef/).**

## License:

pyDecNef2.0 is Â© 2024-2025 by Najemeddine Abdennour & Pedro Margolles & David Soto.

This program is free software: you can redistribute it and/or modify it under the terms of the [GNU General Public License version 3](https://github.com/pedromargolles/pyDecNef/blob/main/LICENSE) as published by the Free Software Foundation.

This program is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. See the GNU General Public License for more details.

Permissions of this strong copyleft license are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved. Contributors provide an express grant of patent rights.


## Introduction:
The project follows the structure provided in [figure 2](structure), where we have two main computers. The first is the server and the second is the client. 
- The server side is the main component and the base of all the pre-processing and decoding operations. This section includes structures to enable receiving  the fMRI data in real-time and pre-process and decode the data as well as dealing with pre-recorded data. 
- The client side is mostly used for direct communication with the experiment participants while they are inside the MRI scanner by providing stimulus and visual feedback as well as receiving the participants responses and reactions that are eventually communicated to the server side.

![structure](.img/file_structure.png)

## Usage and description:

This package relies on the classic DecNef setup and procedure of starting with a decoder training phase, where data is collected to train a decoder, which eventually will be used in the real-time neurofeedback training phase. 
#### I. Data collection for for training:
1. In the initial step of recording the fMRI data, the only part of the package that's in use is the Opensesame script "stimulus_presentation.osexp" on the client side, which is used to display the stimulus to the participant. The script is under the path '2.Client/1.training' , and all details and information on the Opensesame framework and its installation can be found [here](https://osdoc.cogsci.nl/). The log files in CSV format generated by the Opensesame script are needed for the training process since they include the participant's responses. Theses files can be moved to the server side through running the "1.sending_behavior_logs.py" script at the same path. On the server side the "1.receive_behavior_logs.py" script under the path '1.Server/1.model_training/1.Scripts/1.Arranging_data' needs to be run simultaneously as well. (Note: The process of moving the log files in this package is still in the experimental phase and can encounter some issues, alternatively these files can be moved manually by the user.)
2. Before we start the training procedure, we need to pre-process the data. We start with dividing the raw fMRI data according to the runs by running the script "2.divide_raw_fmri_data_to_runs.py" under the path '1.Server/1.model_training/1.Scripts/1.Arranging_data'. The data preprocessing phase is then as simple as running every script under the path '1.Server/1.model_training/1.Scripts/2.preprocessing' in a numerical order. All the generated pre-processed files will be under the path: '1.Server/1.model_training/2.data/preprocessed'. We note that if applying a certain Region of Interest (ROIs) masks is needed for the experiment, the required ROI masks must be placed under the path: '1.Server/1.model_training/2.data/rois_masks'. 
3. Training the decoder requires the use of the scripts under the path: '1.server/1.model_training/1.scripts/3.braindecoder/'. The "1.training_and_evaluating_models_wholebrain.py" is used to train the decoder with the whole brain data and the "2.training_and_evaluating_models_masked.py" is used for the masked data. These scripts offer an optional arguments to choose the type of decoder. The default decoder is the `extratrees` classifier from the scikit learn python library. The list of classifiers is: ["svm", "svmlinear", "decisiontree", "extratree","randomforest", "extratrees", "bagging", "gradientboosting","adaboost", "naivebayes", "kneighbors", "mlp", "sgd","logisticregression" ] , which can be accessed by adding a numerical argument to the script from `0` to `13` following the sequential order of appearance in the list. The argument `14` can be used to evaluate existing models, where the script will execute a leave one run out cross validation test to the decoder with the need of having the decoder named "evaluated_model" and placed under the path '1.Server/1.model_training/3.models/wholebrain' for the whole brain decoder or placed under  '1.Server/1.model_training/3.models/masked/{mask_name}' with {mask_name} is the name of the mask used in training the decoder. In both scripts we also conduct some preprocessing steps that can be removed by changing the variable `preprocessing` to `False` inside the script. The script also product a CSV file `info.csv` that includes the information about the used model and the preprocessing pipeline.
#### II. DecNef real-time training:
1. The neurofeedback phase is handled by the "2.neurofeedback" folders both in the server and the client side.
2. On the sever side, we only need to provide the required resources at the "required_resources" folder,this include:
- the used mask at the training phase inside the path "1.server/2.neurofeedback/required_resources/{subject_tag}/masks" where {subject_tag} corresponds to the tag used for the participants, recommended to be in the form of ex: "sub-1". If no mask was used in the decoder training phase, the mask is supposed to be ` example_func_deoblique_brainmask.nii` that was generated inside the path: "1.server/1.model_training/2.data/preprocessed/example_func/" during the training phase.
- the decoder inside "models"
- the training session reference inside the "training_session_ref_image" folder which is the `example_func_deoblique_brain.nii` file generated during the training phase by "1.model_training/1.scripts/2.preprocessing/1.generate_example_func.py" script.
- the training zscore data inside "training_zscoring_data" folder which include the two files `zscoring_mean_array.npy` and `zscoring_std_array.npy` generated in the training phase inside the "1.model_training/2.data/preprocessed/stacked_vols_of_interest/" folder. In the case that a mask is used this files are named `zscoring_mean_array_{mask_name}.npy` and `zscoring_std_array_{mask_name}.npy` in the "masked_stacked_vols_of_interest_{mask_name}" folder with {mask_name} is the name of the mask used in training.  
- For the case of co-adaptation, the training data and labels of the decoder need to be placed inside "co_adaptation_base_training_stacked_vols_of_interest" folder. These files are `detrended_zscored_stacked_vols_of_interest.nii.gz` and `detrended_zscored_stacked_vols_of_interest_labels.csv` generated in the training phase inside the "1.model_training/2.data/preprocessed/stacked_vols_of_interest/" folder. Even in the case of using masks during the training process, these files are the same.
3. Additionally the `config.ini` file is the main tool to tweak the parameters and change the settings of the neurofeedback pipeline if needed before starting DecNef.
4. After providing the required resources and checking the configuration, we can start the DecNef real-time training by running the `1.realtime_fMRI/run_main.sh` script through the following command `sh run_main.sh`. The script will prompt you for the participant number, session number and run number. Naturally, the script will break or stop functioning if there is something wrong with the parameters or data, For example if you point to the wrong folder path for the participant fMRI data, that we left the default to `/firmm/20240903.test` in the `config.ini` file. 
5. On the client side, we need to run the Opensesame script that corresponds with our desired experiment and presented stimulus. This script is responsible for presenting the stimulus and generating the feedback for the participant during DecNef. The Opensesame script that we provided generates the feedback in the form of a disk, you can read more about it in our [paper](https://doi.org/10.1101/2025.02.21.639408). This script also will generate log files for the runs with details about the decoding accuracy and other important information about the real-time DecNef operation.
6. As convoluted the DecNef Training operation and details for running it correctly, we provided a course of action to make sure everything is ready for the real procedure, through running a simulation. The simulation could be activated by changing the `simulated_experiment` variable to `True` in the `config.ini` file and including pre-recorded fMRI DICOM files in the path "1.server/2.neurofeedback/2.MRI_simulator/real_data". Then, we need to run the `1.server/2.neurofeedback/2.MRI_simulator/generate.py` script to simulate generating new DICOM files similar to the way we do with the MRI scanner, but before that we need to start by running the `1.realtime_fMRI/run_main.sh` script and the Opensesame script the same the way as the real-time DecNef procedure.  
    

### Installation and requirements:
PyDecNef scripts are intended to be run in Python 3.6 or above using as minimum external libraries as possible and relying on Python standard library to maximize compatibility across Python versions.
We also recommend setting up a new conda environment for the package, to have a clean installation of the required packages. The required packages are:
- Pandas
- Nipype
- Nilearn
- scikit-learn
- Colorama

Additionally we used Opensesame 4.0 and Opensesame 4 scripts at the client side for stimuli presentation to the participants. We recommend using python version 3.11.7 since it provided the best compatibility with the scripts and Opensesame 4.0 tool, or you can also check out the Opensesame [documentations](https://osdoc.cogsci.nl/4.0/download/) for more information and details.